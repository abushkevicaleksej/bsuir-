<html>
<HEAD>
<TITLE>Новости с Российского рынка нейрокомпьютеров</TITLE>
</HEAD>

<Body background="../../TEXTURE.GIF" bgcolor="#FFFFFF" MARGINWIDTH="0" LEFTMARGIN="0" TOPMARGIN="0" link="#000080" vlink="#000080"  alink="#0000ff">

<table width=100% border=0 cellpadding=0 cellspacing=0>
 <TR>
  <td ALIGN="RIGHT" VALIGN="TOP" bgColor=#0091d0 background="../../FONTOP.GIF">
    <A HREF="http://neurnews.iu4.bmstu.ru/neurnews.html" TARGET="_top">
    <img src="../../BANNER.JPG" alt="Новости с Российского рынка нейрокомпьютеров и нейроинформационных технологий" border=0></a>
    </td>
  </tr>
</table>

<hr align="center" size="3" color="#000080">

<font FACE="Arial Black" SIZE="4" COLOR="#0000ff">
    </font><font FACE="Arial" SIZE="4" COLOR="#0000ff"><b><a NAME="_Toc424233302">Глава
      10.<br>
      Когнитрон и неокогнитрон</a></li>
    </b></font><font FACE="Times New Roman"><p ALIGN="JUSTIFY">Люди решают
    сложные задачи распознавания образов с
    обескураживающей легкостью. Двухлетний ребенок
    без видимых усилий различает тысячи лиц и других
    объектов, составляющих его окружение, несмотря
    на изменение расстояния, поворота, перспективы и
    освещения.</p>
    <p ALIGN="JUSTIFY">Может показаться, что изучение этих
    врожденных способностей должно сделать простой
    задачу разработки компьютера, повторяющего
    способности человека к распознаванию. Ничто не
    может быть более далеким от истины. Сходство и
    различия образов, являющиеся очевидными для
    человека, пока ставят в тупик даже наиболее
    сложные компьютерные системы распознавания.
    Таким образом, бесчисленное количество важных
    приложений, в которых компьютеры могут заменить
    людей в опасных, скучных или неприятных работах,
    остаются за пределами их текущих возможностей.</p>
    <p ALIGN="JUSTIFY">Компьютерное распознавание образов
    является больше искусством; наука ограничена
    наличием нескольких методик, имеющих
    относительно небольшое использование на
    практике. Инженер, конструирующий типовую
    систему распознавания образов, обычно начинает с
    распознавания печатного текста. Эти методы часто
    являются неадекватными задаче, и старания
    разработчиков быстро сводятся к разработке
    алгоритмов, узко специфичных для данной задачи.</p>
    <p ALIGN="JUSTIFY">Обычно целью конструирования систем
    распознавания образов является оптимизация ее
    функционирования над выборочным набором
    образов. Очень часто разработчик завершает эту
    задачу нахождением нового, приблизительно
    похожего образа, что приводит к неудачному
    завершению алгоритмов. Этот процесс может
    продолжаться неопределенно долго, никогда не
    приводя к устойчивому решению, достаточному для
    повторения процесса восприятия человека,
    оценивающего качество функционирования системы.</p>
    <p ALIGN="JUSTIFY">К счастью, мы имеем существующее
    доказательство того, что задача может быть
    решена: это система восприятия человека.
    Учитывая ограниченность успехов, достигнутых в
    результате стремления к собственным
    изобретениям, кажется вполне логичным вернуться
    к биологическим моделям и попытаться определить,
    каким образом они функционируют так хорошо.
    Очевидно, что это трудно сделать по нескольким
    причинам. Во-первых, сверхвысокая сложность
    человеческого мозга затрудняет понимание
    принципов его функционирования. Трудно понять
    общие принципы функционирования и
    взаимодействия его приблизительно 10</font><sup>11</sup><font
    FACE="Times New Roman"> нейронов и 10</font><sup>14</sup><font
    FACE="Times New Roman"> синаптических связей. Кроме того,
    существует множество проблем при проведении
    экспериментальных исследований.
    Микроскопические исследования требуют
    тщательно подготовленных образцов (заморозка,
    срезы, окраска) для получения маленького
    двумерного взгляда на большую трехмерную
    структуру. Техника микропроб позволяет провести
    исследования внутренней электрохимии узлов,
    однако трудно контролировать одновременно
    большое количество узлов и наблюдать их
    взаимодействие. Наконец, этические соображения
    запрещают многие важные эксперименты, которые
    могут быть выполнены только на людях. Большое
    значение имели эксперименты над животными,
    однако животные не обладают способностями
    человека описывать свои впечатления.</p>
    <p ALIGN="JUSTIFY">Несмотря на эти ограничения, многое
    было изучено благодаря блестяще задуманным
    экспериментам. Например, в [1] описан эксперимент,
    в котором котята выращивались в визуальном
    окружении, состоящем только из горизонтальных
    черных и белых полос. Известно, что определенные
    области коры чувствительны к углу ориентации,
    поэтому у этих котов не развились нейроны,
    чувствительные к вертикальным полосам. Этот
    результат наводит на мысль, что мозг
    млекопитающих не является полностью
    “предустановленным” даже на примитивном уровне
    распознавания ориентации линий. Напротив, он
    постоянно самоорганизуется, основываясь на
    опыте.</p>
    <p ALIGN="JUSTIFY">На микроскопическом уровне
    обнаружено, что нейроны обладают как
    воозбуждающими, так и тормозящими синапсами.
    Первые стремятся к возбуждению нейрона;
    последние подавляют его возбуждение (см.
    приложение А). Это наводит на мысль, что мозг
    адаптируется либо изменением воздействия этих
    синапсов, либо созданием или разрушением
    синапсов в результате воздействия окружающей
    среды. Данное предположение остается пока
    гипотезой с ограниченным физиологическим
    подтверждением. Однако исследования,
    проведенные в рамках этой гипотезы, привели к
    созданию цифровых моделей, некоторые из которых
    показывают замечательные способности к
    адаптивному распознаванию образов.</p>
    <ol>
      <li></font><font FACE="Arial"><b><a NAME="_Toc424233303">КОГНИТРОН</a></li>
      </b></font><font FACE="Times New Roman"><p ALIGN="JUSTIFY">Основываясь на
      текущих знаниях анатомии и физиологии мозга, в
      работе [2] разработан когнитрон, гипотетическая
      модель системы восприятия человека.
      Компьютерные модели, исследованные в [2],
      продемонстрировали впечатляющие способности
      адаптивного распознавания образов, побуждая
      физиологов исследовать соответствующие
      механизмы мозга. Это взаимно усиливающее
      взаимодействие между искусственными нейронными
      сетями, физиологией и психологией может
      оказаться средством, посредством которого будет
      со временем достигнуто понимание механизмов
      мозга</font>.</p>
      <ol>
        <font FACE="Times New Roman"><b>
        <li>Структура</li>
        </b><p ALIGN="JUSTIFY">Когнитрон конструируется в виде
        слоев нейронов, соединенных синапсами. Как
        показано на рис.&nbsp;10.1, предсинаптический нейрон
        в одном слое связан с постсинаптическим нейроном
        в следующем слое. Имеются два типа нейронов:
        возбуждающие узлы, которые стремятся вызвать
        возбуждение постсинаптического узла, и
        тормозящие узлы, которые тормозят это
        возбуждение. Возбуждение нейрона определяется
        взвешенной суммой его возбуждающих и тормозящих
        входов, однако в действительности механизм
        является более сложным, чем простое
        суммирование.</p>
        </font><p ALIGN="CENTER"><img SRC="Image2342.gif" WIDTH="596" HEIGHT="365"></p>
        <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.1.
        Пресинаптические и постсинаптические нейроны</p>
        </b><p ALIGN="JUSTIFY">На рис.&nbsp;10.2 показано, что каждый
        нейрон связан только с нейронами в соседней
        области, называемой <i>областью связи.</i> Это
        ограничение области связи согласуется с
        анатомией зрительной коры, в которой редко
        соединяются между собой нейроны,
        располагающиеся друг от друга на расстоянии
        более одного миллиметра. В рассматриваемой
        модели нейроны упорядочены в виде слоев со
        связями от одного слоя к следующему. Это также
        аналогично послойной структуре зрительной коры
        и других частей головного мозга.</p>
        </font><p ALIGN="CENTER"><img SRC="Image2343.gif" WIDTH="595" HEIGHT="273"></p>
        <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.2. Область
        связей нейрона</p>
        <li>Обучение</li>
      </ol>
      </b><p ALIGN="JUSTIFY">Так как когнитрон реализован в виде
      многослойной сети, возникают сложные проблемы
      обучения, связанные с выбранной структурой.
      Автор отверг управляемое обучение, как
      биологически неправдоподобное, используя взамен
      этого обучение без учителя. Получая обучающий
      набор входных образов, сеть самоорганизуется
      посредством изменения силы синаптических
      связей. При этом отсутствуют предварительно
      определенные выходные образы, представляющие
      требуемую реакцию сети, однако сеть
      самонастраивается с целью распознавания входных
      образов с замечательной точностью.</p>
      <p ALIGN="JUSTIFY">Алгоритм обучения когнитрона является
      концептуально привлекательным. В заданной
      области слоя обучается только наиболее сильно
      возбужденный нейрон. Автор сравнивает это с
      “элитным обучением”, при котором обучаются
      только “умные” элементы. Те нейроны, которые уже
      хорошо обучены, что выражается силой их
      возбуждения, получат приращение силы своих
      синапсов с целью дальнейшего усиления своего
      возбуждения.</p>
      <p ALIGN="JUSTIFY">На рис.&nbsp;10.3 показано, что области
      связи соседних узлов значительно перекрываются.
      Это расточительное дублирование функций
      оправдывается взаимной конкуренцией между
      ближайшими узлами. Даже если узлы в начальный
      момент имеют абсолютно идентичный выход,
      небольшие отклонения всегда имеют место; один из
      узлов всегда будет иметь более сильную реакцию
      на входной образ, чем соседние. Его сильное
      возбуждение будет оказывать сдерживающее
      воздействие на возбуждение соседних узлов, и
      только его синапсы будут усиливаться; синапсы
      соседних узлов останутся неизменными.</p>
      </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Возбуждающий
      нейрон.</b> </font><font FACE="Times New Roman">Грубо говоря, выход
      возбуждающего нейрона в когнитроне определяется
      отношением его возбуждающих входов к тормозящим
      входам. Эта необычная функция имеет важные
      преимущества, как практические, так и
      теоретические.</p>
      </font><p ALIGN="CENTER"><img SRC="Image2344.gif" WIDTH="600" HEIGHT="563"></p>
      <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.3. Область
      связи с областью конкуренции</p>
      </b><p ALIGN="JUSTIFY">Суммарный возбуждающий вход в
      нейрон взвешенной суммой входов от возбуждающих
      предшествующем слое. Аналогично суммарный вход /
      является взвешенной суммой входов от всех
      тормозящих нейронов. В символьном виде</p>
      </font><p><img SRC="Image2345.gif" WIDTH="77" HEIGHT="36">,?<img SRC="Image2346.gif"
      WIDTH="73" HEIGHT="37">,</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где </font><i>a</i><sub>i</sub> – <font
      FACE="Times New Roman">вес </font><i>i</i><font FACE="Times New Roman">-го
      возбуждающего синапса, </font><i>u</i><sub>i</sub> – <font
      FACE="Times New Roman">выход </font><i>i</i><font FACE="Times New Roman">-го
      возбуждающего нейрона,</font> <i>b</i><sub>j</sub> – <font
      FACE="Times New Roman">вес </font><i>j</i><font FACE="Times New Roman">-го
      торозящего синапса, </font><i>v</i><sub>j</sub> – <font
      FACE="Times New Roman">выход </font><i>j</i><font FACE="Times New Roman">-го
      торозящего нейрона.</p>
      <p ALIGN="JUSTIFY">Заметим, что веса имеют только
      положительные значения. Выход нейрона затем
      вычисляется следующим образом:</p>
      </font><p><img SRC="Image2347.gif" WIDTH="108" HEIGHT="41"></p>
      <p ALIGN="JUSTIFY">OUT = NET, <font FACE="Times New Roman">при</font> NET?0,</p>
      <p ALIGN="JUSTIFY">OUT = 0, <font FACE="Times New Roman">при</font> NET&lt;0.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Предполагая, что</font> NET<font
      FACE="Times New Roman"> имеет положительное</font> <font
      FACE="Times New Roman">значение, это можно записать
      следующим образом:</p>
      </font><p><img SRC="Image2348.gif" WIDTH="92" HEIGHT="41"></p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Когда тормозящий вход
      мал (</font><i>I</i> &lt;&lt; 1), OUT<font FACE="Times New Roman"> может быть
      аппроксимировано как</font> </p>
      <p>OUT = <font FACE="Times New Roman"><i>Е</i></font> – <i>I,</p>
      </i><font FACE="Times New Roman"><p ALIGN="JUSTIFY">что соответствует
      выражению для обычного линейного порогового
      элемента (с нулевым порогом).</p>
      <p ALIGN="JUSTIFY">Алгоритм обучения когнитрона
      позволяет весам синапсов возрастать без
      ограничений. Благодаря отсутствию механизма
      уменьшения весов они просто возрастают в
      процессе обучения. В обычных линейных пороговых
      элементах это привело бы к произвольно большому
      выходу элемента. В когнитроне большие
      возбуждающие и тормозящие входы результируются
      в ограничивающей формуле вида:</p>
      </font><p><img SRC="Image2349.gif" WIDTH="88" HEIGHT="41"><font FACE="Times New Roman">,
      если </font><i>E</i><font FACE="Times New Roman"> &gt;&gt; 1 и </font><i>I</i>
      &gt;&gt; 1.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">В данном случае</font> OUT<font
      FACE="Times New Roman"> определяется отношением
      возбуждающих входов к тормозящим входам, а не их
      разностью. Таким образом, величина</font> OUT<font
      FACE="Times New Roman"> ограничивается, если оба входа
      возрастают в одном и том же диапазоне </font><i>X.</i><font
      FACE="Times New Roman"> Предположив, что это так, <i>Е</i> и </font><i>I</i><font
      FACE="Times New Roman"> можно выразить следующим образом:</p>
      </font><p><font FACE="Times New Roman"><i>Е</i></font> = <font FACE="Times New Roman"><i>рХ</i></font>,
      <i>I</i> = <i>qX</i>, <i>p</i>,<i>q</i><font FACE="Times New Roman"> –
      константы,</p>
      <p ALIGN="JUSTIFY">и после некоторых преобразований</p>
      </font><p><img SRC="Image2350.gif" WIDTH="220" HEIGHT="48">.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Эта функция возрастает
      по закону Вебера-Фехнера, который часто
      используется в нейрофизиологии для
      аппроксимации нелинейных соотношений
      входа/выхода сенсорных нейронов. При
      использовании этого соотношения нейрон
      когнитрона в точности эмулирует реакцию
      биологических нейронов. Это делает его как
      мощным вычислительным</font> <font FACE="Times New Roman">элементом,
      так и точной моделью для физиологического
      моделирования.</p>
      </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Тормозящие
      нейроны.</b></font><font FACE="Times New Roman"> В когнитроне слой
      состоит из возбуждающих и тормозящих узлов. Как
      показано на рис.&nbsp;10.4, нейрон слоя</font>&nbsp;<font
      FACE="Times New Roman">2 имеет область связи, для которой он
      имеет синаптические соединения с набором
      выходов нейронов в слое</font>&nbsp;<font FACE="Times New Roman">1.
      Аналогично в слое</font>&nbsp;<font FACE="Times New Roman">1
      существует тормозящий нейрон, имеющий ту же
      область связи. Синаптические веса тормозящих
      узлов не изменяются в процессе обучения; их веса
      заранее установлены таким образом, что сумма
      весов в любом из тормозящих нейронов равна
      единице. В соответствии с этими ограничениями,
      выход тормозящего узла</font> INHIB<font FACE="Times New Roman">
      является взвешенной суммой его входов, которые в
      данном случае представляют собой среднее
      арифметическое выходов возбуждающих нейронов, к
      которым он подсоединен. Таким образом,</p>
      </font><p ALIGN="CENTER"><img SRC="Image2351.gif" WIDTH="594" HEIGHT="396"></p>
      <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.4. Слои
      когнитрона</p>
      </b></font><p><img SRC="Image2352.gif" WIDTH="132" HEIGHT="36">,</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где </font><img SRC="Image2353.gif"
      WIDTH="57" HEIGHT="36">, <i>c</i><sub>i</sub> – <font FACE="Times New Roman">возбуждающий
      вес </font><i>i</i>.</p>
      <font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Процедура обучения.</b>
      </font><font FACE="Times New Roman">Как объяснялось ранее,</font> <font
      FACE="Times New Roman">веса</font> <font FACE="Times New Roman">возбуждающих
      нейронов изменяются только тогда, когда нейрон
      возбужден сильнее, чем любой из узлов в области
      конкуренции. Если это так, изменение в процессе
      обучения любого из его весов может быть
      определено следующим образом:</p>
      <p>?</font><i>a</i><sub>i</sub> = <i>qc</i><sub>j</sub><i>u</i><sub>j</sub>,</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где <i>с</i></font><sub>j</sub> <font
      FACE="Times New Roman">– тормозящий вес связи нейрона </font><i>j</i><font
      FACE="Times New Roman"> в слое</font>&nbsp;<font FACE="Times New Roman">1 с
      тормозящим нейроном </font><i>i</i>, <font FACE="Times New Roman"><i>и</i></font><sub>j</sub>
      <font FACE="Times New Roman">– выход нейрона </font><i>j</i><font
      FACE="Times New Roman"> в слое</font>&nbsp;1, <font FACE="Times New Roman"><i>а</i></font><sub>i</sub>
      – <font FACE="Times New Roman">возбуждающий вес</font> <i>i</i>, <i>q</i>
      -<font FACE="Times New Roman"> нормирующий коэффициент
      обучения.</p>
      <p ALIGN="JUSTIFY">Изменение тормозящих весов нейрона </font><i>i</i><font
      FACE="Times New Roman"> в слое</font>&nbsp;<font FACE="Times New Roman">2
      пропорционально отношению взвешенной суммы
      возбуждающих входов к удвоенному тормозящему
      входу. Вычисления проводятся по формуле</p>
      </font><p><img SRC="Image2354.gif" WIDTH="114" HEIGHT="61">.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Когда возбужденных
      нейронов в области конкуренции нет, для
      изменения весов используются другие выражения.
      Это необходимо, поскольку процесс обучения
      начинается с нулевыми значениями весов; поэтому
      первоначально нет возбужденных нейронов ни в
      одной области конкуренции, и обучение
      производиться не может. Во всех случаях, когда
      победителя в области конкуренции нейронов нет,
      изменение весов нейронов вычисляется следующим
      образом:</p>
      <p>?</font><i>a</i><sub>i</sub> = <i>q</i><b>’</b><i>c</i><sub>j</sub><i>u</i><sub>j</sub>,?<font
      FACE="Times New Roman">?</font><i>b</i><sub>i</sub> = <i>q</i><b>’</b>INHIB,</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где</font> <i>q</i><b>’</b><font
      FACE="Times New Roman"> – положительный обучающий
      коэффициент меньший, чем </font><i>q</i>.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Приведенная стратегия
      настройки гарантирует, что узлы с большой
      реакцией заставляют возбуждающие синапсы,
      которыми они управляют, увеличиваться сильнее,
      чем тормозящие синапсы. И наоборот, узлы, имеющие
      малую реакцию, вызывают малое возрастание
      возбуждающих синапсов, но большее .возрастание
      тормозящих синапсов. Таким образом, если узел</font>&nbsp;<font
      FACE="Times New Roman">1 в слое</font>&nbsp;<font FACE="Times New Roman">1 имеет
      больший выход, синапс <i>а</i></font><sub>1</sub><font
      FACE="Times New Roman"> возрастет больше, чем синапс </font><i>b</i><sub>1</sub><i>.</i><font
      FACE="Times New Roman"> И наоборот, узлы, имеющие малый
      выход, обеспечат малую величину для приращения <i>а</i></font><sub>i</sub>.<font
      FACE="Times New Roman"> Однако другие узлы в области связи
      будут возбуждаться, тем самым увеличивая сигнал
      INHIB и значения </font><i>b</i><sub>i</sub>.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">В процессе обучения
      веса каждого узла в слое</font>&nbsp;<font FACE="Times New Roman">2
      настраиваются таким образом, что вместе они
      составляют шаблон, соответствующий образам,
      которые часто предъявляются в процессе обучения.
      При предъявлении сходного образа шаблон
      соответствует ему и узел вырабатывает большой
      выходной сигнал. Сильно отличающийся образ
      вырабатывает малый выход и обычно подавляется
      конкуренцией.</p>
      </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Латеральное
      торможение.</b> </font><font FACE="Times New Roman">На рис.</font>&nbsp;<font
      FACE="Times New Roman">10.4 показано, что каждый нейрон слоя</font>&nbsp;<font
      FACE="Times New Roman">2 получает латеральное торможение от
      нейронов, расположенных в его области
      конкуренции. Тормозящий нейрон суммирует входы
      от всех нейронов в области конкуренции и
      вырабатывает сигнал, стремящийся к торможению
      целевого нейрона. Этот метод является эффектным,
      но с вычислительной точки зрения медленным. Он
      охватывает большую систему с обратной связью,
      включающую каждый нейрон в слое; для его
      стабилизации может потребоваться большое
      количество вычислительных итераций.</p>
      <p ALIGN="JUSTIFY">Для ускорения вычислений в работе [2]
      используется остроумный метод ускоренного
      латерального торможения (рис.</font>&nbsp;<font
      FACE="Times New Roman">10.5). Здесь дополнительный узел
      латерального торможения обрабатывает выход
      каждого возбуждающего узла для моделирования
      требуемого латерального торможения. Сначала он
      определяет сигнал, равный суммарному
      тормозящему влиянию в области конкуренции:</p>
      </font><p ALIGN="CENTER"><img SRC="Image2355.gif" WIDTH="594" HEIGHT="369"></p>
      <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.5. Ускоренное
      торможение</p>
      </b></font><p><img SRC="Image2356.gif" WIDTH="173" HEIGHT="36">,</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где</font> OUT<sub>i</sub> –<font
      FACE="Times New Roman"> выход </font><i>i-</i><font FACE="Times New Roman">го
      нейрона в области конкуренции,</font> <i>g</i><sub>i</sub> – <font
      FACE="Times New Roman">вес связи от этого нейрона к
      латерально</font>-<font FACE="Times New Roman">тормозящему</font> <font
      FACE="Times New Roman">нейрону; </font><i>g</i><sub>i</sub><font
      FACE="Times New Roman"> выбраны таким образом, что</font> <img
      SRC="Image2357.gif" WIDTH="60" HEIGHT="36">.</p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Выход тормозящего
      нейрона</font> OUT<b>’</b><font FACE="Times New Roman"> затем
      вычисляется</font> <font FACE="Times New Roman">следующим
      образом:</p>
      </font><p><img SRC="Image2358.gif" WIDTH="181" HEIGHT="46"></p>
      <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Благодаря тому что все
      вычисления, связанные с таким типом латерального
      торможения, являются нерекурсивными, они могут
      быть проведены за один проход для слоя, тем самым
      определяя эффект в виде большой экономии в
      вычислениях.</p>
      <p ALIGN="JUSTIFY">Этот метод латерального торможения
      решает и другую сложную проблему. Предположим,
      что узел в .слое 2 возбуждается сильно, но
      возбуждение соседних узлов уменьшается
      постепенно с увеличением расстояния. При
      использовании обычного латерального торможения
      будет обучаться только центральный узел. Другие
      узлы определяют, что центральный узел в их
      области конкуренции имеет более высокий выход. С
      предлагаемой системой латерального торможения
      такой ситуации случиться не может. Множество
      узлов может обучаться одновременно и процесс
      обучения является более достоверным.</p>
      </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Рецептивная
      область.</b> </font><font FACE="Times New Roman">Анализ, проводимый
      до этого момента, был упрощен рассмотрением
      только одномерных слоев. В действительности
      когнитрон конструировался как каскад двумерных
      слоев, причем в данном слое каждый нейрон
      получает входы от набора нейронов на части
      двумерного плана, составляющей его область связи
      в предыдущем слое.</p>
      <p ALIGN="JUSTIFY">С этой точки зрения когнитрон
      организован подобно зрительной коре человека,
      представляющей собой трехмерную структуру,
      состоящую из нескольких различных слоев.
      Оказывается, что каждый слой мозга реализует
      различные уровни обобщения; входной слой
      чувствителен к простым образам, таким, как линии,
      и их ориентации в определенных областях
      визуальной области, в то время как реакция других
      слоев является более сложной, абстрактной и
      независимой от позиции образа.</p>
      <p ALIGN="JUSTIFY">Аналогичные функции реализованы в
      когнитроне путем моделирования организации
      зрительной коры. На рис.&nbsp;</font>1<font FACE="Times New Roman">0.6
      показано, что нейроны когнитрона в слое&nbsp;2
      реагируют на определенную небольшую область
      входного слоя&nbsp;1. Нейрон в слое&nbsp;3 связан с
      набором нейронов слоя&nbsp;2, тем самым реагируя
      косвенно на более широкий набор нейронов
      слоя&nbsp;1. Подобным образом нейроны в последующих
      слоях чувствительны к более широким областям
      входного образа до тех пор, пока в выходном слое
      каждый нейрон не станет реагировать на все
      входное поле.</p>
      <p ALIGN="JUSTIFY">Если область связи нейронов имеет
      постоянный размер во всех слоях, требуется
      большое количество слоев для перекрытия всего
      входного поля выходными нейронами. Количество
      слоев может быть уменьшено путем расширения
      области связи в последующих слоях. К сожалению,
      результатом этого может явиться настолько
      большое перекрытие областей связи, что нейроны
      выходного слоя будут иметь одинаковую реакцию.
      Для решения этой проблемы может быть
      использовано расширение области конкуренции.
      Так как в данной области конкуренции может
      возбудиться только один узел, влияние малой
      разницы в реакциях нейронов выходного слоя
      усиливается.</p>
      </font><p ALIGN="CENTER"><img SRC="Image2359.gif" WIDTH="603" HEIGHT="170"></p>
      <font FACE="Times New Roman"><b><p ALIGN="CENTER">Рис.&nbsp;10.6. Области
      связей когнитрона</p>
      </b><p ALIGN="JUSTIFY">В альтернативном варианте связи с
      предыдущим слоем могут быть распределены
      вероятностно с большинством синаптических
      связей в ограниченной области и с более длинными
      соединениями, встречающимися намного реже. Это
      отражает вероятностное распределение нейронов,
      обнаруженное в мозге. В когнитроне это позволяет
      каждому нейрону выходного слоя реагировать на
      полное входное поле при наличии ограниченного
      количества слоев.</p>
      </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Результаты
      моделирования.</b> </font><font FACE="Times New Roman">В [4]
      описываются результаты компьютерного
      моделирования четырехслойного когнитрона,
      предназначенного для целей распознавания
      образов. Каждый слой состоит из массива 12</font><font
      FACE="Arial">х</font><font FACE="Times New Roman">12 возбуждающих
      нейронов и такого же количества тормозящих
      нейронов. Область связи представляет собой
      квадрат, включающий 5</font><font FACE="Arial">х</font><font
      FACE="Times New Roman">5 нейронов. Область конкуренции
      имеет форму ромба высотой и шириной в пять
      нейронов. Латеральное торможение охватывает
      область 7</font><font FACE="Arial">х</font><font FACE="Times New Roman">7
      нейронов. Нормирующие параметры обучения
      установлены таким образом, что </font><i>q</i><font
      FACE="Times New Roman">=16,0 и</font> <i>q</i><b>’</b>=2,0.<font FACE="Times New Roman">
      Веса синапсов проинициализированы в 0.</p>
      <p ALIGN="JUSTIFY">Сеть обучалась путем предъявления
      пяти стимулирующих образов, представляющих
      собой изображения арабских цифр от</font>&nbsp;<font
      FACE="Times New Roman">0 до</font>&nbsp;<font FACE="Times New Roman">4, на
      входном слое. Веса сети настраивались после
      предъявления каждой цифры, входной набор
      подавался на вход сети циклически до тех пор,
      пока каждый образ не был предъявлен суммарно 20</font>&nbsp;<font
      FACE="Times New Roman">раз.</p>
      <p ALIGN="JUSTIFY">Эффективность процесса обучения
      оценивалась путем запуска сети в реверсивном
      режиме; выходные образы, являющиеся реакцией
      сети, подавались на выходные нейроны и
      распространялись обратно к входному слою.
      Образы, полученные во входном слое, затем
      сравнивались с исходным входным образом. Чтобы
      сделать это, обычные однонаправленные связи
      принимались проводящими в обратном направлении
      и латеральное торможение отключалось. На
      рис.&nbsp;10.7 показаны типичные результаты
      тестирования. В столбце</font>&nbsp;<font FACE="Times New Roman">2
      показаны образы, произведенные каждой цифрой на
      выходе сети. Эти образы возвращались обратно,
      вырабатывая на входе сети образ, близкий к точной
      копии исходного входного образа. Для столбца</font>&nbsp;<font
      FACE="Times New Roman">4 на выход сети подавался только
      выход нейрона, имеющего максимальное
      возбуждение. Результирующие образы в точности те
      же, что и в случае подачи полного выходного
      образа, за исключением цифры</font>&nbsp;<font
      FACE="Times New Roman">0, для которой узел с максимальным
      выходом располагался на периферии и не покрывал
      полностью входного поля.</p>
      </font><p ALIGN="CENTER"><img SRC="Image2360.gif" WIDTH="595" HEIGHT="361"></p>
      <b><font FACE="Times New Roman"><p ALIGN="CENTER">Рис.&nbsp;10.7. Результаты
      экспериментов с когнитроном</p>
      </font>
      <li><font FACE="Arial"><a NAME="_Toc424233304">НЕОКОГНИТРОН</a></li>
      </font></b><font FACE="Times New Roman"><p ALIGN="JUSTIFY">В попытках
      улучшить когнитрон была разработана мощная
      парадигма, названная <i>неокогнитрон</i> [5–7]. В то
      время как когнитрон и неокогнитрон имеют
      определенное сходство, между ними также
      существуют фундаментальные различия, связанные
      с эволюцией исследований авторов. Оба образца
      являются многоуровневыми иерархическими сетями,
      организованными аналогично зрительной коре. В то
      же время неокогнитрон более соответствует
      модели зрительной системы, предложенной в
      работах [10–12]. В результате неокогнитрон
      является намного более мощной парадигмой с точки
      зрения способности распознавать образы
      независимо от их преобразований, вращении,
      искажений и изменений масштаба. Как и когнитрон,
      неокогнитрон использует самоорганизацию в
      процессе обучения, хотя была описана версия [9], в
      которой вместо этого использовалось управляемое</font>
      <font FACE="Times New Roman">обучение.</p>
      <p ALIGN="JUSTIFY">Неокогнитрон ориентирован на
      моделирование зрительной системы человека. Он
      получает на входе двумерные образы, аналогичные
      изображениям на сетчатой оболочке глаза, и
      обрабатывает их в последующих слоях аналогично
      тому, как это было обнаружено в зрительной коре
      человека. Конечно, в неокогнитроне нет ничего,
      ограничивающего его использование только для
      обработки визуальных данных, он достаточно
      универсален и может найти широкое применение как
      обобщенная система распознавания образов.</p>
      <p ALIGN="JUSTIFY">В зрительной коре были обнаружены
      узлы, реагирующие на такие элементы, как линии и
      углы определенной ориентации. На более высоких
      уровнях узлы реагируют на более сложные и
      абстрактные образы такие, как окружности,
      треугольники и прямоугольники. На еще более
      высоких уровнях степень абстракции возрастает
      до тех пор, пока не определятся узлы, реагирующие
      на лица и сложные формы. В общем случае узлы на
      более высоких уровнях получают вход от группы
      низкоуровневых узлов и, следовательно, реагируют
      на более широкую область визуального поля.
      Реакции узлов более высокого уровня менее
      зависят от позиции и более устойчивы к
      искажениям.</p>
      <ol>
        <b>
        <li>Структура</li>
        </b><p ALIGN="JUSTIFY">Неокогнитрон имеет иерархическую
        структуру, ориентированную на моделирование
        зрительной системы человека. Он состоит из
        последовательности обрабатывающих слоев,
        организованных в иерархическую структуру
        (рис.&nbsp;10.8). Входной образ подается на первый слой
        и передается через плоскости, соответствующие
        последующим слоям, до тех пор, пока не достигнет
        выходного слоя, в котором идентифицируется
        распознаваемый образ.</p>
        </font><b><p ALIGN="CENTER"><img SRC="Image2361.gif" WIDTH="594" HEIGHT="164"></p>
        <font FACE="Times New Roman"><p ALIGN="CENTER">Рис.&nbsp;10.8. Структура
        слоев неокогнитрона</p>
        </b><p ALIGN="JUSTIFY">Структура неокогнитрона трудна для
        представления в виде диаграммы, но концептуально
        проста. Чтобы подчеркнуть его многоуровневость
        (с целью упрощения графического представления),
        используется анализ верхнего уровня.
        Неокогнитрон показан состоящим из слоев, слои
        состоят из набора плоскостей и плоскости состоят
        из узлов.</p>
        </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Слои. </b></font><font
        FACE="Times New Roman">Каждый слой неокогнитрона состоит
        из двух массивов плоскостей (рис.&nbsp;10.9). Массив
        плоскостей, содержащих простые узлы, получает
        выходы предыдущего слоя, выделяет определенные
        образы и затем передает их в массив плоскостей,
        содержащих комплексные узлы, где они
        обрабатываются таким образом, чтобы сделать
        выделенные образы менее позиционно зависимыми.</p>
        </font><font FACE="Arial" SIZE="2"><b><p ALIGN="JUSTIFY">Плоскости. </b></font><font
        FACE="Times New Roman">Внутри слоя плоскости простых и
        комплексных узлов существуют парами, т.&nbsp;е. для
        плоскости простых узлов существует одна
        плоскость комплексных узлов, обрабатывающая ее
        выходы. Каждая плоскость может быть визуально
        представлена как двумерный массив узлов.</p>
        </font><p ALIGN="CENTER"><img SRC="Image2362.gif" WIDTH="598" HEIGHT="422"></p>
        <b><font FACE="Times New Roman"><p ALIGN="CENTER">Рис.&nbsp;10.9. Структура
        плоскостей неокогнитрона</p>
        </font><font FACE="Arial" SIZE="2"><p ALIGN="JUSTIFY">Простые</b> <b>узлы. </b></font><font
        FACE="Times New Roman">Все узлы в данной плоскости простых
        узлов реагируют на один и тот же образ. Как
        показано на рис.&nbsp;10.10, плоскость простых узлов
        представляет массив узлов, каждый из которых
        “настраивается” на один специфический входной
        образ. Каждый простой узел чувствителен к
        ограниченной области входного образа,
        называемой его рецептивной областью. Например,
        все узлы в верхней плоскости простых узлов на
        рис.&nbsp;10.10 реагируют на “С”. Узел реагирует, если
        “С” встречается во входном образе и если “С”
        обнаружено в его рецептивной области.</p>
        <p ALIGN="JUSTIFY">На рис.&nbsp;10.10 показано, что другие
        плоскости простых узлов в этом слое могут
        реагировать на поворот “С” на 90°, другие на
        поворот на 180° и т.&nbsp;д. Если должны быть выделены
        другие буквы (и их искаженные версии),
        дополнительные плоскости требуются для каждой
        из них.</p>
        <p ALIGN="JUSTIFY">Рецептивные области узлов в каждой
        плоскости простых узлов перекрываются с целью
        покрытия всего входного образа этого слоя.
        Каждый узел получает входы от соответствующих
        областей всех плоскостей комплексных узлов в
        предыдущем слое. Следовательно, простой узел
        реагирует на появление своего образа в любой
        сложной плоскости предыдущего слоя, если он
        окажется внутри его рецептивной области.</p>
        </font><p ALIGN="CENTER"><img SRC="Image2363.gif" WIDTH="600" HEIGHT="493"></p>
        <b><font FACE="Times New Roman"><p ALIGN="CENTER">Рис.&nbsp;10.10. Система
        неокогнитрона</p>
        </font><font FACE="Arial" SIZE="2"><p ALIGN="JUSTIFY">Комплексные узлы.</b>
        </font><font FACE="Times New Roman">Задачей комплексных узлов
        является уменьшение зависимости реакции системы
        от позиции образов во входном поле. Для
        достижения этого каждый комплексный узел
        получает в качестве входного образа выходы
        набора простых узлов из соответствующей
        плоскости того же слоя.</font> <font FACE="Times New Roman">Эти
        простые узлы покрывают непрерывную область
        простой плоскости, называемую рецептивной
        областью комплексного узла. Возбуждение любого
        простого узла в этой области является
        достаточным для возбуждения данного
        комплексного узла. Таким образом, комплексный</font>
        <font FACE="Times New Roman">узел реагирует на тот же образ,
        что и простые узлы в соответствующей ему
        плоскости, но он менее чувствителен к позиции
        образа, чем любой из них.</p>
        <p ALIGN="JUSTIFY">Таким образом, каждый слой комплексных
        узлов реагирует на более широкую область
        входного образа, чем это делалось в
        предшествующих слоях. Эта прогрессия возрастает
        линейно от слоя к слою, приводя к требуемому
        уменьшению позиционной чувствительности
        системы в целом.</p>
        <b>
        <li>Обобщение</li>
        </b><p ALIGN="JUSTIFY">Каждый нейрон в слое, близком к
        входному, реагирует на определенные образы в
        определенном месте, такие, как угол с
        определенной ориентацией в заданной позиции.
        Каждый слой в результате этого имеет более
        абстрактную, менее специфичную реакцию по
        сравнению с предшествующим; выходной слой
        реагирует на полные образы, показывая высокую
        степень независимости от их положения, размера и
        ориентации во входном поле. При использовании в
        качестве классификатора комплексный узел
        выходного слоя с наибольшей реакцией реализует
        выделение соответствующего образа во входном
        поле. В идеальном случае это выделение
        нечувствительно к позиции, орентации, размерам
        или другим искажениям.</p>
        <b>
        <li>Вычисления</li>
        </b><p ALIGN="JUSTIFY">Простые узлы в неокогнитроне имеют
        точно такие же характеристики, что и описанные
        для когнитрона, и используют те же формулы для
        определения их выхода. Здесь они не повторяются</font>.</p>
        <font FACE="Times New Roman"><p ALIGN="JUSTIFY">Тормозящий узел
        вырабатывает выход, пропорциональный
        квадратному корню из взвешенной суммы квадратов
        его входов. Заметим, что входы в тормозящий узел
        идентичны входам соответствующего простого узла
        и область включает область ответа во всех
        комплексных плоскостях. В символьном виде</p>
        </font><p><img SRC="Image2364.gif" WIDTH="104" HEIGHT="41">,</p>
        <font FACE="Times New Roman"><p ALIGN="JUSTIFY">где</font> <i>v</i><font
        FACE="Times New Roman"> – выход тормозящего узла;</font> <i>i</i>
        –<font FACE="Times New Roman"> область над всеми комплексными
        узлами, с которыми связан тормозящий узел; </font><i>b</i><sub>i</sub>
        <i>–</i><font FACE="Times New Roman"> вес </font><i>i</i>-<font
        FACE="Times New Roman">й синаптической связи от
        комплексного узла к тормозящему узлу; </font><i>u</i><sub>i</sub>
        <font FACE="Times New Roman">– выход </font><i>i</i>-<font FACE="Times New Roman">го
        комплексного узла.</p>
        <p ALIGN="JUSTIFY">Веса </font><i>b</i><sub>i</sub><font FACE="Times New Roman">
        выбираются монотонно уменьшающимися с
        увеличением расстояния от центра области
        реакции, при этом сумма их значений должна быть
        равна единице.</p>
        <b>
        <li>Обучение</li>
      </ol>
    </ol>
  </ol>
</ol>
</b>

<p ALIGN="JUSTIFY">Только простые узлы имеют
настраиваемые веса. Это веса связей, соединяющих
узел с комплексными узлами в предыдущем слое и
имеющих изменяемую силу синапсов, настраиваемую
таким образом, чтобы выработать максимальную
реакцию на определенные стимулирующие свойства.
Некоторые из этих синапсов являются
возбуждающими и стремятся увеличить выход узлов,
в то время как другие являются тормозящими и
уменьшают выход узла.</p>
</font>

<p ALIGN="CENTER"><img SRC="Image2365.gif" WIDTH="595" HEIGHT="409"></p>
<b><font FACE="Times New Roman">

<p ALIGN="CENTER">Рис.&nbsp;10.11. Связи от сложных клеток
одного уровня </font><br>
<font FACE="Times New Roman">к простым клеткам следующего
уровня</p>
</b>

<p ALIGN="JUSTIFY">На рис.&nbsp;10.11 показана полная
структура синаптических связей между простым
узлом и комплексными узлами в предшествующем
слое. Каждый простой узел реагирует только на
набор комплексных узлов внутри своей
рецептивной области. Кроме того, существует
тормозящий узел, реагирующий на те же самые
комплексные узлы. Веса синапсов тормозящего узла
не обучаются, – они выбираются таким образом,
чтобы узел реагировал на среднюю величину
выходов всех узлов, к которым он подключен.
Единственный тормозящий синапс от тормозящего
узла к простому узлу обучается, как и другие
синапсы.</p>
</font><font FACE="Arial" SIZE="2"><b>

<p ALIGN="JUSTIFY">Обучение без учителя.</b> </font><font
FACE="Times New Roman">Для обучения неокогнитрона на вход
сети подается образ, который необходимо
распознать, и веса синапсов настраиваются слой
за слоем, начиная с набора простых узлов,
ближайших ко входу. Величина синаптической связи
от каждого комплексного узла к данному простому
узлу увеличивается тогда и только тогда, когда
удовлетворяются следующие два условия:</p>

<ol>
  <li>комплексный узел реагирует;</li>
  <li>простой узел реагирует более сильно, чем любой
    из его соседних (внутри его области конкуренции).</li>
</ol>

<p ALIGN="JUSTIFY">Таким образом, простой узел обучается
реагировать более сильно на образы, появляющиеся
наиболее часто в его рецептивной области, что
соответствует результатам исследований,
полученных в экспериментах с котятами. Если
распознаваемый образ отсутствует на входе,
тормозящий узел предохраняет от случайного
возбуждения.</p>

<p ALIGN="JUSTIFY">Математическое описание процесса
обучения и метод реализации латерального
торможения аналогичны описанным для когнитрона,
поэтому здесь они не повторяются. Необходимо
отметить, что выходы простых и комплексных узлов
являются аналоговыми, непрерывными и линейными и
что алгоритм обучения предполагает их
неотрицательность.</p>

<p ALIGN="JUSTIFY">Когда выбирается простой узел, веса
синапсов которого должны быть увеличены, он
рассматривается как представитель всех узлов в
плоскости, вызывая увеличение их синаптических
связей на том же самом образе. Таким образом, все
узлы в плоскости обучаются распознавать одни и
те же свойства, и после обучения будут делать это
независимо от позиции образа в поле комплексных
узлов в предшествующем слое.</p>

<p ALIGN="JUSTIFY">Эта система имеет ценную способность к
самовосстановлению. Если данный узел выйдет из
строя, будет найден другой узел, реагирующий
более сильно, и этот узел будет обучен
распознаванию входного образа, тем самым
перекрывая действия своего отказавшего
товарища.</p>
</font><font FACE="Arial" SIZE="2"><b>

<p ALIGN="JUSTIFY">Обучение с учителем.</b> </font><font
FACE="Times New Roman">В работах [3] и [8] описано
самоорганизующееся неуправляемое обучение.
Наряду с этими впечатляющими результатами, были
опубликованы отчеты о других экспериментах,
использующих обучение с учителем [9]. Здесь
требуемая реакция каждого слоя заранее
определяется экспериментатором. Затем веса
настраиваются с использованием обычных методов
для выработки требуемой реакции. Например,
входной слой настраивался для распознавания
отрезков линий в различных ориентациях во многом
аналогично первому слою обработки зрительной
коры. Последующие слои обучались реагировать на
более сложные и абстрактные свойства до тех пор,
пока в выходном слое требуемый образ не будет
выделен. При обработке сети, превосходно
распознающей рукописные арабские цифры,
экспериментаторы отказались от достижения
биологического правдоподобия, обращая внимание
только на достижение максимальной точности
результатов системы.</p>
</font><font FACE="Arial" SIZE="2"><b>

<p ALIGN="JUSTIFY">Реализация обучения.</b> </font><font
FACE="Times New Roman">В обычных конфигурациях рецептивное
поле каждого нейрона возрастает при переходе к
следующему слою. Однако количество нейронов в
слое будет уменьшаться при переходе от входных к
выходным слоям. Наконец, выходной слой имеет
только один нейрон в плоскости сложных узлов.
Каждый такой нейрон представляет определенный
входной образ, которому сеть была обучена. В
процессе классификации входной образ подается
на вход неокогнитрона и вычисляются выходы слой
за слоем, начиная с входного слоя. Так как только
небольшая часть входного образа подается на вход
каждого простого узла входного слоя, некоторые
простые узлы регистрируют наличие
характеристик, которым они обучены, и
возбуждаются. В следующем слое выделяются более
сложные характеристики как определенные
комбинации выходов комплексных узлов. Слои за
слоем свойства комбинируются во все
возрастающем диапазоне; выделяются более общие
характеристики и уменьшается позиционная
чувствительность.</p>

<p ALIGN="JUSTIFY">В идеальном случае только один нейрон
выходного слоя должен возбудиться. В
действительности обычно будет возбуждаться
несколько нейронов с различной силой, и входной
образ должен быть определен с учетом соотношения
их выходов. Если используется сила латерального
торможения, возбуждаться будет только нейрон с
максимальным выходом. Однако это часто является
не лучшим вариантом. На практике простая функция
от небольшой группы наиболее сильно
возбужденных нейронов будет часто улучшать
точность классификации.</p>

<ol>
  <ol>
    <ol>
      <li></font><font FACE="Arial"><b><a NAME="_Toc424233305">ЗАКЛЮЧЕНИЕ</a></li>
      </b></font><font FACE="Times New Roman"><p ALIGN="JUSTIFY">Как когнитрон,
      так и неокогнитрон производят большое
      впечатление с точки зрения точности, с которой
      они моделируют биологическую нервную систему.
      Тот факт, что эти системы показывают результаты,
      имитирующие некоторые аспекты способностей
      человека к обучению и познанию, наводит на мысль,
      что наше понимание функций мозга приближается к
      уровню, способному принести практическую пользу.</p>
   